## 처리율 제한 장치란?
rate limiter, 처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)을 제어(limit)하기 위한 장치이다.<br>
특정 기간 내 전송되는 클라이언트의 요청 횟수를 제한하여<br>
API 요청 횟수가 제한 장치에 정의된 임계치를 넘어서면, 추가로 전달된 모든 호출은 처리가 block(중단)된다.

## 사례
- 사용자는 초당 2회 이상 새 글을 올릴 수 없다
- 같은 IP주소로 하루에 10개 이상 계정을 생성할 수 없다
- 같은 디바이스로 주당 5회 이상 리워드(reward) 요청할 수 없다.

이러한 처리율을 제한하는 장치를 설계해보자.

## 처리율 제한 장치를 API에 두면 좋은 점은 무엇일까?
1. 자원 고갈을 방지할 수 있다. (Denial of Service, DoS공격에 의해 발생 가능)
  - twitter : 3시간 동안 300개의 트윗만 올릴 수 있다.
  - 구글 독스 API : 사용자당 분당 300회의 read 요청만 허용된다.
  - 결국 추가 요청에 대해서는 처리 중단하여 DoS공격 방지할 수 있다.
2. 추가 요청에 대한 처리를 제한하므로 비용을 절감할 수 있다.
3. 서버 과부하를 막는다.
	- 봇이나 사용자의 잘못된 패턴으로 발생하는 트래픽을 걸러내는데 처리율 제한 장치를 활용할 수 있다.


# 1단계. 문제 이해 및 설계 범위 확정
처리율 제한 장치를 구현하는 데는 여러 알고리즘을 사용할 수 있고, 각각 고유한 장단점이 있다.

먼저 면접관과 소통하면서 어떤 제한 장치를 구현해야하는지 분명히 하고, 설계 범위를 확정짓자.

어떤 궁금증이 떠오르는가? 궁금한 것을 면접관에게 질문하자.

- 처리율 제한 장치가 어느 쪽의 제한 장치인지?   클라이언트 vs "서버"
- 어떤 기준으로 API 호출을 제어해야할까?    "다양한 형태의 제어 규칙을 정의할 수 있도록 하는 유연한 시스템"
- 시스템 규모  "대규모 요청을 처리할 수 있는"
- 시스템이 분산환경에서 동작하는가?  "YES"
- 독립된 서비스 vs 애플리케션 코드에 포함?   "I can choose"
- 사용자에게 요청이 제한된 사실을 알려야 하는가?   "YES" 

## 요구사항
- 설정된 처리율을 초과하는 요청은 정확히 제한한다. 
- 응답 시간이 낮아야 한다. HTTP 응답 시간에 나쁜 영향을 주면 곤란!
- 가능한 한 적은 메모리 사용
- 분산형 : 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.
- 예외 처리 : 요청이 제한 되었을 때는 사용자에게 명확히 알려주어야 한다. 
- 높은 결함 감내성 : 제한 장치에 장애가 발생하더라도 전체 시스템에는 영향을 주어서는 안된다.

---
# 2단계. 개략적 설계안 제시 및 동의 구하기
일단 일을 너무 복잡하게 만들지 말고, 기본적인 client-server 통신 모델을 사용하자.
(덧붙여서, 추상적인 것은 구체화하고 복잡한 것은 단순화하는 것이 면접자에게 유리한 접근 방향인 듯하다.)

### 1) 처리율 제한 장치를 어디에 둘까?
클라이언트 요청은 쉽게 위변조가 가능해서 모든 클라이언트 요청을 완전히 통제하는 것은 어려울 수 있다.
서버측에 둔다면, 2가지 방법이 있다.
a. API 서버 내에 장치를 두는 것 (함께 묶음)
b. API 서버 앞에 처리율 제한 middleware를 두는 것 : API로 서버로 가는 요청을 통제한다.

다음과 같이 나타낼 수 있다.

"초당 2개의 요청으로 제한"하는 상황에서, 같은 초 범위 내에 3번째 요청을 처리율 제한 장치에 의해 막히고, 클라이언트에게는 HTTP 상태 코드(ex- 429, Too many request)를 통해 알린다.

클라우드 마이크로서비스를 예로 들면, 처리율 제한 장치는 'API 게이트웨이'라 불리는 컴포넌트 내에 구현되어있다.
API 게이트웨이 또한 미들웨어로서 처리율 제한 외에도 많은 역할(SSL 종단, 사용자 인증, IP 허용 목록 관리 등..)을 지원하는 fully managed 서비스이다. (즉, 클라우드 업체가 유지 보수를 담당하는 서비스!)

*그럼 서버와 미들웨어(게이트웨이) 중 어디에 둬야하나?*<br>
상황에 따라 선택이 달라질 수 있는데 **일반적으로 적용되는 지침**은 아래와 같다.
- 현재 회사에서 사용하고 있는 기술 스택을 점검하자. 현재 사용하는 프로그래밍 언어가 서버 측에 구현하는 것을 지원하기 충분한만큼 효율이 높은가를 확인하자.
- 필요에 맞는 처리율 제한 알고리즘을 찾아야 하는데, 서버 측에 구현한다면 알고리즘을 자유롭게 선택할 수 있지만 제3사업자가 제공하는 게이트웨이를 사용한다면 선택지가 제한된다.
- 이 장치가 적용되는 설계가 마이크로서비스에 기반하고 있고, 이미 API 게이트웨이를 다른 목적으로 설계에 포함시켰다면 해당 장치 또한 게이트웨이에 포함시키는게 나을 수 있다.
- 직접 만들기에 인력이 부족하다면 상용 API 게이트웨이를 쓰는 것이 바람직하다.

### 2) 처리율 제한 알고리즘 5가지
'[4장. 처리율 제한 장치의 설계 - 알고리즘 편](obsidian://open?vault=moonz's%20personal%20space&file=3.%20%EC%9E%90%EA%B8%B0%EA%B3%84%EB%B0%9C%2F%EA%B3%B5%EB%B6%80%2F%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88%2F4%EC%9E%A5.%20%EC%B2%98%EB%A6%AC%EC%9C%A8%20%EC%A0%9C%ED%95%9C%20%EC%9E%A5%EC%B9%98%EC%9D%98%20%EC%84%A4%EA%B3%84%20-%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%ED%8E%B8)'을 참고하자.


### 3) 개략적인 아키텍처
추적 대상별로 얼마나 많은 요청이 접수되는지 추적할 수 있는 카운터를 두고,
이 카운터의 값이 한도치를 넘어서면, 그때 오는 요청들은 거부하는 것이다.

*이때 추적 대상을 사용자로 할 것인지, IP 주소 별 or API 엔드포인트 별 or 서비스 단위 별로 할지 결정해야한다.

그리고 이 카운터 값은 어디에 보관할까?<br>db는 디스크 접근 때문에 느리므로 메모리상에서 동작하는 캐시가 바람직하다. (why? 빠르고, 시간에 기반한 만료 정책을 지원)
<br>일례로 Redis는 처리율 제한 장치를 구현할 때 자주 사용되는 메모리 기반 저장장치로, `INCR`&`EXPIRE` 두가지 명령어 지원한다.
- `INCR` : 메모리에 저장된 카운터 값을 1만큼 증가
- `EXPIRE` : 카운터에 타임아웃 값을 설정한다. 설정된 시간이 지나면 카운터가 자동으로 삭제된다.

<br>동작원리
1. 클라이언트가 처리율 제한 미들웨어에게 요청을 보낸다.
2. 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와 한도치를 체크한다.
	1. 한도에 도달헀다면 요청 거부
	2. 한도에 도달하지 않았다면 API 서버에게 전달하고, 카운터의 값을 1 증가시킨 후 레디스에 저장한다.


*"문든 든 생각. 회사에서는 처리율 제한 장치가 미들웨어 (api gateway)에 함께 적용돼있을까? 실제 어떻게 적용되었을지 궁금한데"<br>
-> 현재 구현되어있지 않고, k8s가 도입되면 자동으로 함께 적용되는 것으로 파악! 어떤 설정으로 그게 되는거지?*

---
# 3단계. 상세 설계
개략적인 아키텍처 설계를 했다면, 아래와 같은 구체적인 사항을 정의해보자.
- 처리율 제한 규칙은 어떻게 만들어지고 어디에 저장될까?
- 처리가 제한된 요청들은 어떻게 처리될까?


알아볼 사항
1. 처리율 제한 규칙
2. 처리가 제한된 요청의 처리 전략
3. 분산 환경에서의 처리율 제한 기법
4. 구체적인 설계/성능 최적화 방안/모니터링 방안 등...


## 3-1. 처리율 제한 규칙
> [Lyft 의 처리율 제한 오픈소스]()를 확인하자.

아래와 같은 처리율 제한 규칙은 **config 파일 형태**로 디스크에 저장된다.
1) 마케팅 메시지의 최대치를 하루 5개로 제한한다.
```yml
domain: messaging
descriptors:
	- key: message_type
	  value: marketing
	  rate_limit:
		  unit: day
		  request_per_unit: 5
```

2) 로그인 시도 횟수를 분당 5회로 제한한다.
```yml
domain: auth
descriptors:
	- key: auth_type
	  value: login
	  rate_limit:
		  unit: minute
		  request_per_unit: 5
```


## 3-2. 처리가 제한된 요청의 처리 전략
어떤 요청이 한도 제한에 걸리면 API는 **HTTP 429 응답 (too many requests)**을 클라이언트에게 보낸다.<br>
경우에 따라 제한 걸린 메시지를 큐에 보관할 수도 있다. <br>ex) 주문이 시스템 과부하 때문에 한도제한에 걸렸다면 해당 주문들을 큐에 보관했다가 나중에 처리한다.

> 처리율 제한 장치가 사용하는 HTTP 헤더<br>
> 처리율 제한 장치는 클라이언트에게 HTTP 응답 헤더(resoonse header)에 값을 담아서<br클라이언트 요청이 처리율 제한에 걸리고 있는지, 처리율 제한에 걸리기까지 몇개의 요청을 보낼 수 있는 지 알려준다. 
> - `X-Ratelimit-Remaining` : 윈도 내에 남은 처리 가능 요청 수
> - `X-Ratelimit-Limit` : 매 윈도마다 클라이언트가 전송할 수 있는 요청 수
> - `X-Ratelimit-Retry-After` : 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야하는지 알림<br>
> 만약 클라이언트 요청이 제한에 걸리고 있다면, 429 오류를 `X-Ratelimit-Retry-After` 헤더와 함께 반환한다.


### 상세 설계
1. 작업 프로세스는 수시로  디스크에 보관된 처리율 제한 규칙을 읽어서 캐시에 저장한다.
2. 클라이언트가 요청을 서버에 보내면, 요청은 처리율 제한 미들웨어에 먼저 도착한다.
3. 제한 규칙을 캐시에서 가져오고, 카운터 & 마지막 요청의 타임스탬프를 레디스에서 가져온다.
4. 가져온 값들들에 근거해서 아래와 같은 결정을 내린다.
	1. 요청이 처리율 제한에 걸리지 않은 경우 API 서버로 전달
	2. 요청이 처리율 제한에 걸린 경우 클라이언트에게 429 too many requests 에러값을 보낸다.
		1. 이때 요청을  그대로 버리거나 메시지 큐에 보관할 수 있다.


## 3-3. 분산 환경에서의 처리율 제한 기법
수백만 사용자를 지원하려면 여러대의 서버와 병렬 스레드를 지원하도록 시스템을 확장하는 것은 1. 경쟁 조건(race condition) 2. 동기화(synchronization) 문제를 고려해야 한다. 🌟🌟🌟


#### 1) 경쟁 조건
처리율 제한 장치는
1. 레디스에서 카운터 값을 읽어서
2. 카운터 + 1 값이 임계치를 넘는지 확인한 후
3. 넘지 않으면 레디스에 보관된 카운터 값을 1만큼 증가시킨다.

병행성이 심한 환경에서는 두 서버가 동일 데이터를 동시에 읽고, 값이 1만 증가하는 문제의 '경쟁 조건 이슈'가 발생한다.

> 해결 방법
> 1. 락(lock)은 시스템의 성능을 상당히 떨어뜨린다.
> 2. 루아 스크림트 (Lua script) ([참고](https://stripe.com/blog/rate-limiters))
> 3. 정렬 집합 (sorted set) - 레디스 자료구조 ([참고](https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/))


#### 2) 동기화 이슈
다수의 처리율 제한 장치 서버들끼리는 동기화가 필요한데, <br>클라이언트 1이 제한 장치 1에 요청을 보내고, 클라이언트 2가 제한 장치 2에 요청을 보냈다고 했을 때,<br>웹 게층은 무상태이기 때문에 클라이언트 2가 두번 째 요청을 제한 장치 1에 보낼 수 있다.<br>동기화하지 않다면, 제한 장치 1은 클라이언트 2에 대해서 모르므로 요청 횟수를 1개 보낸 것으로 처리할 것이다.<br>결국, 처리율 제한을 올바르게 수행하지 못할 것이다.

> 해결 방법
> 1. 고정 세션 (sticky session) 활용한다. *but, 규모 면에서 확장 가능하지 않고 유연하지 않기 때문에 추천 X*
> 2. 레디스 같은 중앙 집중형 데이터 저장소를 사용하는 것 추천!!    *-> 구체적인 방법 알아볼 필요있음.* 🌟🌟


## 3-4. 구체적인 설계/성능 최적화 방안/모니터링 방안 등... 
1) 성능 최적화 
	1) 지연 시간 : 데이터 센터에서 멀리 떨어진 사용자에 대한 지연 시간 증가 문제를 줄이기 위해, 사용자의 트래픽을 가장 가까운 에지 서비스로 전달한다.
	2) 데이터 동기화 : 최종 일관성 모델 사용하는 것 고려
2) 모니터링 : 효과적으로 동작하고 있는지 보기 위해 데이터를 모아서 볼 수 있다. 
	1) 채택된 처리율 제한 알고리즘이 효과적인가? 트래픽이 급증하는 순간에 비효율적으로 동작하지 않은가? 트래픽 패턴에 따라 알고리즘을 바꿔야하진 않는가?  (ex- 토큰 버킷 적합)
	2) 정의된 처리율 제한 규칙이 효과적인가? 너무 빡빡하게 설정되지 않았는가?


## 3-5. 시간이 된다면 그 외에도 다룰만한 주제..
- 경성(hard) 또는 연성(soft) 처리율 제한
- 다양한 계층에서의 처리율 제한
	- 이번에는 7계층(애플리케이션 계층)에서 진행했지만, 다른 계층에서도 가능하다.
	- 3계층, IP 주소에 처리율 제한을 적용하는 것도 가능하다. (Iptables 사용)
- 처리율 제한 회피 방법 : 클라이언트를 어떻게 설계하는 것이 최선인가?
	- 클라이언트 측 캐시 사용해서 API 호출 횟수 줄인다.
	- 처리율 제한의 임계치 이해하여, 짧은 시간동안 너무 많은 메시지를 보내지 않도록 한다.
	- 예외나 에러를 처리하는 코드 도입 -> 클라이언트가 예외 상황으로부터 우아하게 복구하도록 한다.
	- 재시도 로직 구현 시에는 충분한 백오프 시간을 둔다.

Nginx에 직접 적용한 사례 : https://willseungh0.tistory.com/191
-> 프론트에 두는 것의 단점.
